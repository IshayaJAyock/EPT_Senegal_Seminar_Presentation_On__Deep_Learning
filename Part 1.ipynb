{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the **First** implementation of deep learning using keras framework.  \n",
    "A dataset of 6000 observation and 10 features was randolmly generated \n",
    "to build the network with a binary classification type of problem.    \n",
    "Furthermore, a validation set of 2000 observation was also generated ramdomly to  \n",
    "to be used for the validation set in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages of interest importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential #  to build the model\n",
    "from keras.layers import Dense, Activation # For stacking layers and adding activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a dummy dataset for the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7) # fixing random seed for reproducibility\n",
    "\n",
    "X_train = np.random.random((6000,10)) \n",
    "\n",
    "Y_train = np.random.randint(2, size=(6000, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a dummy dataset for validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = np.random.random((2000,10))\n",
    "y_val = np.random.randint(2, size=(2000, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a dummy dataset test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.random.random((2000,10))\n",
    "y_test = np.random.randint(2, size=(2000, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the 4 major steps for implement MLP models in deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Modeling architecture for the prolblem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() #creating the sequential model object.\n",
    "\n",
    "# Stacking the layers to our network\n",
    "model.add(Dense(128, input_dim=10, activation = \"relu\")) #input and hidden Layer 1\n",
    "model.add(Dense(64, activation = \"relu\"))               # hidden Layer 2\n",
    "model.add(Dense(64, activation = \"relu\"))               # hidden Layer 2\n",
    "model.add(Dense(32,activation = \"relu\"))               # hidden Layer 3\n",
    "model.add(Dense(16,activation = \"relu\"))                # hidden Layer 4\n",
    "model.add(Dense(8,activation = \"relu\"))                # hidden Layer 5\n",
    "model.add(Dense(1,activation = \"sigmoid\"))             #Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We then Configure the model using the compile method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model to learn the pattern from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5128 - val_loss: 0.6935 - val_accuracy: 0.4995\n",
      "Epoch 2/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5135 - val_loss: 0.6938 - val_accuracy: 0.4935\n",
      "Epoch 3/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5125 - val_loss: 0.6938 - val_accuracy: 0.4935\n",
      "Epoch 4/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5132 - val_loss: 0.6935 - val_accuracy: 0.4975\n",
      "Epoch 5/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5182 - val_loss: 0.6939 - val_accuracy: 0.4980\n",
      "Epoch 6/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5250 - val_loss: 0.6941 - val_accuracy: 0.4940\n",
      "Epoch 7/15\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.5187 - val_loss: 0.6940 - val_accuracy: 0.5050\n",
      "Epoch 8/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5037 - val_loss: 0.6934 - val_accuracy: 0.4875\n",
      "Epoch 9/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5135 - val_loss: 0.6942 - val_accuracy: 0.4980\n",
      "Epoch 10/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5230 - val_loss: 0.6938 - val_accuracy: 0.4890\n",
      "Epoch 11/15\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.6911 - accuracy: 0.5265 - val_loss: 0.6939 - val_accuracy: 0.5010\n",
      "Epoch 12/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5380 - val_loss: 0.6941 - val_accuracy: 0.5095\n",
      "Epoch 13/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.5302 - val_loss: 0.6963 - val_accuracy: 0.4935\n",
      "Epoch 14/15\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6944 - val_accuracy: 0.4975\n",
      "Epoch 15/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5140 - val_loss: 0.6945 - val_accuracy: 0.4945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3d9c0945d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=128, epochs=15, validation_data = (x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5095\n",
      "[0.6932476162910461, 0.5095000267028809]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the boston housing dataset which came along with the the keras module, to build the network.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will download the data using Keras;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import boston_housing # Importing the dataset from the keras framework\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the data structure of the trianing and testing examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of training data : (404, 13)\n",
      "Dimension of testing data : (102, 13)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimension of training data :\",x_train.shape)\n",
    "print(\"Dimension of testing data :\",x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the last 100 rows from the training data to create the validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[300:,]\n",
    "y_val = y_train[300:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(6, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam',metrics=['mean_absolute_percentage_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 580.4777 - mean_absolute_percentage_error: 99.2924 - val_loss: 669.0395 - val_mean_absolute_percentage_error: 98.6468\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 563.2446 - mean_absolute_percentage_error: 97.0546 - val_loss: 636.2152 - val_mean_absolute_percentage_error: 95.0837\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 519.4225 - mean_absolute_percentage_error: 91.1984 - val_loss: 566.6072 - val_mean_absolute_percentage_error: 87.1837\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 436.9371 - mean_absolute_percentage_error: 79.4052 - val_loss: 448.6432 - val_mean_absolute_percentage_error: 72.1382\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 313.7859 - mean_absolute_percentage_error: 61.0884 - val_loss: 295.0734 - val_mean_absolute_percentage_error: 50.4860\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 189.5531 - mean_absolute_percentage_error: 44.6658 - val_loss: 170.9775 - val_mean_absolute_percentage_error: 37.5660\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 126.8135 - mean_absolute_percentage_error: 42.6856 - val_loss: 137.2184 - val_mean_absolute_percentage_error: 40.6108\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 121.6782 - mean_absolute_percentage_error: 46.2848 - val_loss: 132.4517 - val_mean_absolute_percentage_error: 39.6616\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 114.4309 - mean_absolute_percentage_error: 43.0893 - val_loss: 130.2735 - val_mean_absolute_percentage_error: 37.0690\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 109.7202 - mean_absolute_percentage_error: 40.3228 - val_loss: 127.8914 - val_mean_absolute_percentage_error: 35.4574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efcb43388d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=32, epochs=10,validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 703us/step - loss: 124.5002 - mean_absolute_percentage_error: 47.1769\n",
      "loss  :  124.5002212524414\n",
      "mean_absolute_percentage_error  :  47.17692947387695\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test)\n",
    "for i in range(len(model.metrics_names)):\n",
    "    print(model.metrics_names[i],\" : \", results[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model again with different set of parameters parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 105.8067 - mean_absolute_percentage_error: 38.5289 - val_loss: 123.5191 - val_mean_absolute_percentage_error: 34.5658\n",
      "Epoch 2/30\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 100.9711 - mean_absolute_percentage_error: 38.1070 - val_loss: 117.0187 - val_mean_absolute_percentage_error: 34.6272\n",
      "Epoch 3/30\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 97.3378 - mean_absolute_percentage_error: 37.8824 - val_loss: 113.1113 - val_mean_absolute_percentage_error: 33.7908\n",
      "Epoch 4/30\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 93.4430 - mean_absolute_percentage_error: 36.6298 - val_loss: 109.8901 - val_mean_absolute_percentage_error: 32.7481\n",
      "Epoch 5/30\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 89.9179 - mean_absolute_percentage_error: 35.3236 - val_loss: 106.9467 - val_mean_absolute_percentage_error: 31.6891\n",
      "Epoch 6/30\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 86.8376 - mean_absolute_percentage_error: 34.4931 - val_loss: 103.8942 - val_mean_absolute_percentage_error: 30.8020\n",
      "Epoch 7/30\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 83.9205 - mean_absolute_percentage_error: 33.1260 - val_loss: 101.5635 - val_mean_absolute_percentage_error: 29.7752\n",
      "Epoch 8/30\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 81.4629 - mean_absolute_percentage_error: 33.4516 - val_loss: 97.7104 - val_mean_absolute_percentage_error: 29.8062\n",
      "Epoch 9/30\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 78.6560 - mean_absolute_percentage_error: 32.3133 - val_loss: 96.4219 - val_mean_absolute_percentage_error: 28.4360\n",
      "Epoch 10/30\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 76.3952 - mean_absolute_percentage_error: 31.4570 - val_loss: 94.2635 - val_mean_absolute_percentage_error: 27.8907\n",
      "Epoch 11/30\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 74.2610 - mean_absolute_percentage_error: 31.0342 - val_loss: 92.0331 - val_mean_absolute_percentage_error: 27.6147\n",
      "Epoch 12/30\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 72.5412 - mean_absolute_percentage_error: 30.8589 - val_loss: 90.9033 - val_mean_absolute_percentage_error: 26.7667\n",
      "Epoch 13/30\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 71.0164 - mean_absolute_percentage_error: 29.9892 - val_loss: 89.6935 - val_mean_absolute_percentage_error: 26.1145\n",
      "Epoch 14/30\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 70.2001 - mean_absolute_percentage_error: 30.8883 - val_loss: 87.2770 - val_mean_absolute_percentage_error: 26.5033\n",
      "Epoch 15/30\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 68.4487 - mean_absolute_percentage_error: 29.5396 - val_loss: 87.9347 - val_mean_absolute_percentage_error: 25.0156\n",
      "Epoch 16/30\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 67.3018 - mean_absolute_percentage_error: 29.3305 - val_loss: 86.4727 - val_mean_absolute_percentage_error: 25.1756\n",
      "Epoch 17/30\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 66.6640 - mean_absolute_percentage_error: 29.0119 - val_loss: 85.8418 - val_mean_absolute_percentage_error: 24.9462\n",
      "Epoch 18/30\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 65.9604 - mean_absolute_percentage_error: 29.1192 - val_loss: 85.4184 - val_mean_absolute_percentage_error: 24.6946\n",
      "Epoch 19/30\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 65.2041 - mean_absolute_percentage_error: 29.0042 - val_loss: 84.2896 - val_mean_absolute_percentage_error: 25.0577\n",
      "Epoch 20/30\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 64.8364 - mean_absolute_percentage_error: 29.3293 - val_loss: 84.1689 - val_mean_absolute_percentage_error: 24.8727\n",
      "Epoch 21/30\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 64.4934 - mean_absolute_percentage_error: 29.4250 - val_loss: 83.5347 - val_mean_absolute_percentage_error: 25.0611\n",
      "Epoch 22/30\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 64.1671 - mean_absolute_percentage_error: 29.5389 - val_loss: 84.0079 - val_mean_absolute_percentage_error: 24.6206\n",
      "Epoch 23/30\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 63.8540 - mean_absolute_percentage_error: 28.3490 - val_loss: 84.7627 - val_mean_absolute_percentage_error: 24.2695\n",
      "Epoch 24/30\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 63.7320 - mean_absolute_percentage_error: 28.7515 - val_loss: 82.9092 - val_mean_absolute_percentage_error: 24.9232\n",
      "Epoch 25/30\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 63.6170 - mean_absolute_percentage_error: 28.2741 - val_loss: 83.5585 - val_mean_absolute_percentage_error: 24.4805\n",
      "Epoch 26/30\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 63.0369 - mean_absolute_percentage_error: 28.8059 - val_loss: 82.5485 - val_mean_absolute_percentage_error: 24.8120\n",
      "Epoch 27/30\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 62.6572 - mean_absolute_percentage_error: 28.4703 - val_loss: 82.6891 - val_mean_absolute_percentage_error: 24.5864\n",
      "Epoch 28/30\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 62.4121 - mean_absolute_percentage_error: 27.9907 - val_loss: 82.6551 - val_mean_absolute_percentage_error: 24.4477\n",
      "Epoch 29/30\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 62.2169 - mean_absolute_percentage_error: 28.7919 - val_loss: 81.5424 - val_mean_absolute_percentage_error: 24.9483\n",
      "Epoch 30/30\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 61.9500 - mean_absolute_percentage_error: 27.8215 - val_loss: 82.5068 - val_mean_absolute_percentage_error: 24.1841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efcb41c68d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=32, epochs=30,validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 821us/step - loss: 67.2585 - mean_absolute_percentage_error: 32.0259\n",
      "loss  :  67.25848388671875\n",
      "mean_absolute_percentage_error  :  32.02594757080078\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test)\n",
    "for i in range(len(model.metrics_names)):\n",
    "    print(model.metrics_names[i],\" : \", results[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the abve two models we can see that mean  \n",
    "absolute error dcreases with increase in the number of epocks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the Hello World of Machine learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing and splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 726us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 635us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 926us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 702us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 801us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 863us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 962us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 934us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 718us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 805us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 910us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 826us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 640us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 939us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 812us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 856us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 906us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 822us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 687us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 680us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 838us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 803us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 593us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 732us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 931us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 578us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 802us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 735us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 937us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 775us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 772us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 682us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 856us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 657us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 964us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 885us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 747us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 672us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 759us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 603us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 868us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 849us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 691us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 964us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 668us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 918us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 988us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 690us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 679us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 692us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 759us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 699us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 651us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 665us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 616us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 603us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 673us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 638us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 674us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 721us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 634us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 881us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 684us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 675us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 612us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 784us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 641us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 773us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 882us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 622us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 685us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 810us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 730us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 631us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 660us/step - loss: 0.6417 - accuracy: 0.3583\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 712us/step - loss: 0.6417 - accuracy: 0.3583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efcbc4a1ed0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Dense(activation='relu', \n",
    "                                input_dim=4, units=4, kernel_initializer='uniform'))\n",
    "model.add(tf.keras.layers.Dense(activation='relu', \n",
    "                                units=4, kernel_initializer='uniform'))\n",
    "model.add(tf.keras.layers.Dense(activation='sigmoid', units=1,kernel_initializer='uniform'))\n",
    "model.add(tf.keras.layers.Dense(1,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=10,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting values from the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot of test values-vs-predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_test, y_pred)\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r*--')\n",
    "ax.set_xlabel('Calculated')\n",
    "ax.set_ylabel('Predictions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset of interest \"pima indians dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"Pima-Indians-Diabetes.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input (X) and output (Y) variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,0:8]\n",
    "Y = dataset.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(64, kernel_initializer='uniform', activation= 'relu'))\n",
    "model.add(Dense(64, kernel_initializer='uniform', activation= 'relu'))\n",
    "model.add(Dense(32, kernel_initializer='uniform', activation= 'relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform', activation= 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the  model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss= 'binary_crossentropy' , optimizer= 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6738 - accuracy: 0.6510\n",
      "Epoch 2/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6404 - accuracy: 0.6471\n",
      "Epoch 3/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6393 - accuracy: 0.6615\n",
      "Epoch 4/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6440 - accuracy: 0.6602\n",
      "Epoch 5/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6167 - accuracy: 0.6497\n",
      "Epoch 6/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6167 - accuracy: 0.6641\n",
      "Epoch 7/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6076 - accuracy: 0.6862\n",
      "Epoch 8/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5994 - accuracy: 0.6901\n",
      "Epoch 9/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5954 - accuracy: 0.6706\n",
      "Epoch 10/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5909 - accuracy: 0.6784\n",
      "Epoch 11/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5846 - accuracy: 0.6992\n",
      "Epoch 12/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5774 - accuracy: 0.7005\n",
      "Epoch 13/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5813 - accuracy: 0.7018\n",
      "Epoch 14/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5793 - accuracy: 0.6940\n",
      "Epoch 15/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5750 - accuracy: 0.7344\n",
      "Epoch 16/200\n",
      "77/77 [==============================] - 0s 980us/step - loss: 0.5617 - accuracy: 0.7240\n",
      "Epoch 17/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5605 - accuracy: 0.7214\n",
      "Epoch 18/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5588 - accuracy: 0.7331\n",
      "Epoch 19/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5558 - accuracy: 0.7383\n",
      "Epoch 20/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5806 - accuracy: 0.6849\n",
      "Epoch 21/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5451 - accuracy: 0.7318\n",
      "Epoch 22/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5362 - accuracy: 0.7370\n",
      "Epoch 23/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5326 - accuracy: 0.7474\n",
      "Epoch 24/200\n",
      "77/77 [==============================] - 0s 985us/step - loss: 0.5411 - accuracy: 0.7253\n",
      "Epoch 25/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5417 - accuracy: 0.7174\n",
      "Epoch 26/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5260 - accuracy: 0.7370\n",
      "Epoch 27/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5206 - accuracy: 0.7474\n",
      "Epoch 28/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5270 - accuracy: 0.7500\n",
      "Epoch 29/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5075 - accuracy: 0.7448\n",
      "Epoch 30/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5122 - accuracy: 0.7500\n",
      "Epoch 31/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5347 - accuracy: 0.7357\n",
      "Epoch 32/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5170 - accuracy: 0.7604\n",
      "Epoch 33/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5005 - accuracy: 0.7591\n",
      "Epoch 34/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5004 - accuracy: 0.7656\n",
      "Epoch 35/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4955 - accuracy: 0.7578\n",
      "Epoch 36/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4913 - accuracy: 0.7604\n",
      "Epoch 37/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5009 - accuracy: 0.7500\n",
      "Epoch 38/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5036 - accuracy: 0.7565\n",
      "Epoch 39/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4883 - accuracy: 0.7721\n",
      "Epoch 40/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4872 - accuracy: 0.7747\n",
      "Epoch 41/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4833 - accuracy: 0.7539\n",
      "Epoch 42/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5044 - accuracy: 0.7630\n",
      "Epoch 43/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4883 - accuracy: 0.7656\n",
      "Epoch 44/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4775 - accuracy: 0.7708\n",
      "Epoch 45/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4761 - accuracy: 0.7643\n",
      "Epoch 46/200\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7669\n",
      "Epoch 47/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4748 - accuracy: 0.7695\n",
      "Epoch 48/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4820 - accuracy: 0.7487\n",
      "Epoch 49/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7695\n",
      "Epoch 50/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4949 - accuracy: 0.7565\n",
      "Epoch 51/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4679 - accuracy: 0.7734\n",
      "Epoch 52/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4620 - accuracy: 0.7721\n",
      "Epoch 53/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4702 - accuracy: 0.7734\n",
      "Epoch 54/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.7773\n",
      "Epoch 55/200\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7826\n",
      "Epoch 56/200\n",
      "77/77 [==============================] - 0s 988us/step - loss: 0.4494 - accuracy: 0.7852\n",
      "Epoch 57/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4564 - accuracy: 0.7799\n",
      "Epoch 58/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4461 - accuracy: 0.7826\n",
      "Epoch 59/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4734 - accuracy: 0.7773\n",
      "Epoch 60/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4552 - accuracy: 0.7865\n",
      "Epoch 61/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4725 - accuracy: 0.7773\n",
      "Epoch 62/200\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7865\n",
      "Epoch 63/200\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.7904\n",
      "Epoch 64/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4536 - accuracy: 0.7734\n",
      "Epoch 65/200\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7852\n",
      "Epoch 66/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4430 - accuracy: 0.7878\n",
      "Epoch 67/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4593 - accuracy: 0.7891\n",
      "Epoch 68/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.7656\n",
      "Epoch 69/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4505 - accuracy: 0.7721\n",
      "Epoch 70/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4477 - accuracy: 0.7812\n",
      "Epoch 71/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4573 - accuracy: 0.7760\n",
      "Epoch 72/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4684 - accuracy: 0.7760\n",
      "Epoch 73/200\n",
      "77/77 [==============================] - 0s 894us/step - loss: 0.4532 - accuracy: 0.7799\n",
      "Epoch 74/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4506 - accuracy: 0.7695\n",
      "Epoch 75/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4356 - accuracy: 0.7865\n",
      "Epoch 76/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4574 - accuracy: 0.7643\n",
      "Epoch 77/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4443 - accuracy: 0.7891\n",
      "Epoch 78/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4354 - accuracy: 0.7786\n",
      "Epoch 79/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4499 - accuracy: 0.7773\n",
      "Epoch 80/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.7812\n",
      "Epoch 81/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4427 - accuracy: 0.7891\n",
      "Epoch 82/200\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7839\n",
      "Epoch 83/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4346 - accuracy: 0.7982\n",
      "Epoch 84/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.7917\n",
      "Epoch 85/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4443 - accuracy: 0.7930\n",
      "Epoch 86/200\n",
      "77/77 [==============================] - 0s 872us/step - loss: 0.4407 - accuracy: 0.7760\n",
      "Epoch 87/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4384 - accuracy: 0.7773\n",
      "Epoch 88/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4289 - accuracy: 0.7956\n",
      "Epoch 89/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4309 - accuracy: 0.7930\n",
      "Epoch 90/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4286 - accuracy: 0.7969\n",
      "Epoch 91/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4344 - accuracy: 0.7930\n",
      "Epoch 92/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4364 - accuracy: 0.7852\n",
      "Epoch 93/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4185 - accuracy: 0.7956\n",
      "Epoch 94/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4337 - accuracy: 0.7904\n",
      "Epoch 95/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.7943\n",
      "Epoch 96/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4155 - accuracy: 0.8125\n",
      "Epoch 97/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4439 - accuracy: 0.7852\n",
      "Epoch 98/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4220 - accuracy: 0.7917\n",
      "Epoch 99/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4221 - accuracy: 0.7930\n",
      "Epoch 100/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4323 - accuracy: 0.7891\n",
      "Epoch 101/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4244 - accuracy: 0.8008\n",
      "Epoch 102/200\n",
      "77/77 [==============================] - 0s 948us/step - loss: 0.4316 - accuracy: 0.7982\n",
      "Epoch 103/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4374 - accuracy: 0.7865\n",
      "Epoch 104/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4302 - accuracy: 0.7878\n",
      "Epoch 105/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4069 - accuracy: 0.8151\n",
      "Epoch 106/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4129 - accuracy: 0.8047\n",
      "Epoch 107/200\n",
      "77/77 [==============================] - 0s 979us/step - loss: 0.4352 - accuracy: 0.7852\n",
      "Epoch 108/200\n",
      "77/77 [==============================] - 0s 883us/step - loss: 0.4249 - accuracy: 0.8034\n",
      "Epoch 109/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4132 - accuracy: 0.8008\n",
      "Epoch 110/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4205 - accuracy: 0.8151\n",
      "Epoch 111/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4243 - accuracy: 0.7956\n",
      "Epoch 112/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4294 - accuracy: 0.7943\n",
      "Epoch 113/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4257 - accuracy: 0.7917\n",
      "Epoch 114/200\n",
      "77/77 [==============================] - 0s 977us/step - loss: 0.4074 - accuracy: 0.8099\n",
      "Epoch 115/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.7904\n",
      "Epoch 116/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4074 - accuracy: 0.8073\n",
      "Epoch 117/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4203 - accuracy: 0.7969\n",
      "Epoch 118/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4151 - accuracy: 0.7956\n",
      "Epoch 119/200\n",
      "77/77 [==============================] - 0s 972us/step - loss: 0.4118 - accuracy: 0.8047\n",
      "Epoch 120/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4195 - accuracy: 0.7904\n",
      "Epoch 121/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4044 - accuracy: 0.8008\n",
      "Epoch 122/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4203 - accuracy: 0.7943\n",
      "Epoch 123/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4028 - accuracy: 0.8151\n",
      "Epoch 124/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3975 - accuracy: 0.8138\n",
      "Epoch 125/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4102 - accuracy: 0.8060\n",
      "Epoch 126/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4037 - accuracy: 0.7982\n",
      "Epoch 127/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4099 - accuracy: 0.8047\n",
      "Epoch 128/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4176 - accuracy: 0.7995\n",
      "Epoch 129/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4083 - accuracy: 0.8112\n",
      "Epoch 130/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4025 - accuracy: 0.8125\n",
      "Epoch 131/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4107 - accuracy: 0.8125\n",
      "Epoch 132/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3996 - accuracy: 0.8112\n",
      "Epoch 133/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3926 - accuracy: 0.8229\n",
      "Epoch 134/200\n",
      "77/77 [==============================] - 0s 914us/step - loss: 0.4014 - accuracy: 0.8229\n",
      "Epoch 135/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4029 - accuracy: 0.7995\n",
      "Epoch 136/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4106 - accuracy: 0.7956\n",
      "Epoch 137/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3994 - accuracy: 0.8086\n",
      "Epoch 138/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3892 - accuracy: 0.8073\n",
      "Epoch 139/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4146 - accuracy: 0.8086\n",
      "Epoch 140/200\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.8177\n",
      "Epoch 141/200\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3969 - accuracy: 0.7995\n",
      "Epoch 142/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4006 - accuracy: 0.8073\n",
      "Epoch 143/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4182 - accuracy: 0.8060\n",
      "Epoch 144/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3836 - accuracy: 0.8099\n",
      "Epoch 145/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3934 - accuracy: 0.8125\n",
      "Epoch 146/200\n",
      "77/77 [==============================] - 0s 938us/step - loss: 0.3890 - accuracy: 0.8151\n",
      "Epoch 147/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3879 - accuracy: 0.8216\n",
      "Epoch 148/200\n",
      "77/77 [==============================] - 0s 883us/step - loss: 0.4040 - accuracy: 0.8021\n",
      "Epoch 149/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4186 - accuracy: 0.8112\n",
      "Epoch 150/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3970 - accuracy: 0.8112\n",
      "Epoch 151/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3952 - accuracy: 0.7982\n",
      "Epoch 152/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3856 - accuracy: 0.8099\n",
      "Epoch 153/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4050 - accuracy: 0.8008\n",
      "Epoch 154/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3929 - accuracy: 0.8086\n",
      "Epoch 155/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3866 - accuracy: 0.8190\n",
      "Epoch 156/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4066 - accuracy: 0.8099\n",
      "Epoch 157/200\n",
      "77/77 [==============================] - 0s 911us/step - loss: 0.4045 - accuracy: 0.7995\n",
      "Epoch 158/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4001 - accuracy: 0.8086\n",
      "Epoch 159/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3839 - accuracy: 0.8138\n",
      "Epoch 160/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3750 - accuracy: 0.8190\n",
      "Epoch 161/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3787 - accuracy: 0.8216\n",
      "Epoch 162/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3814 - accuracy: 0.8190\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3918 - accuracy: 0.8138\n",
      "Epoch 164/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3779 - accuracy: 0.8242\n",
      "Epoch 165/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3823 - accuracy: 0.8190\n",
      "Epoch 166/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3801 - accuracy: 0.8125\n",
      "Epoch 167/200\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3997 - accuracy: 0.7956\n",
      "Epoch 168/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3934 - accuracy: 0.8060\n",
      "Epoch 169/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3920 - accuracy: 0.8112\n",
      "Epoch 170/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3851 - accuracy: 0.8034\n",
      "Epoch 171/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3690 - accuracy: 0.8294\n",
      "Epoch 172/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3903 - accuracy: 0.8190\n",
      "Epoch 173/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3777 - accuracy: 0.8177\n",
      "Epoch 174/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3736 - accuracy: 0.8268\n",
      "Epoch 175/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3769 - accuracy: 0.8138\n",
      "Epoch 176/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3739 - accuracy: 0.8216\n",
      "Epoch 177/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3833 - accuracy: 0.8177\n",
      "Epoch 178/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3721 - accuracy: 0.8229\n",
      "Epoch 179/200\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8164\n",
      "Epoch 180/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3667 - accuracy: 0.8281\n",
      "Epoch 181/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3637 - accuracy: 0.8229\n",
      "Epoch 182/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3923 - accuracy: 0.8216\n",
      "Epoch 183/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3636 - accuracy: 0.8333\n",
      "Epoch 184/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3736 - accuracy: 0.8242\n",
      "Epoch 185/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3654 - accuracy: 0.8255\n",
      "Epoch 186/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3971 - accuracy: 0.8021\n",
      "Epoch 187/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3860 - accuracy: 0.8255\n",
      "Epoch 188/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3634 - accuracy: 0.8320\n",
      "Epoch 189/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3866 - accuracy: 0.8177\n",
      "Epoch 190/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3609 - accuracy: 0.8385\n",
      "Epoch 191/200\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3609 - accuracy: 0.8294\n",
      "Epoch 192/200\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3811 - accuracy: 0.8112\n",
      "Epoch 193/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3698 - accuracy: 0.8229\n",
      "Epoch 194/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3690 - accuracy: 0.8372\n",
      "Epoch 195/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3752 - accuracy: 0.8164\n",
      "Epoch 196/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3673 - accuracy: 0.8216\n",
      "Epoch 197/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3570 - accuracy: 0.8385\n",
      "Epoch 198/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3639 - accuracy: 0.8359\n",
      "Epoch 199/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3653 - accuracy: 0.8411\n",
      "Epoch 200/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3650 - accuracy: 0.8294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3cfaaf2850>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=200, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 568us/step - loss: 0.3570 - accuracy: 0.8359\n",
      "accuracy: 83.59%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
